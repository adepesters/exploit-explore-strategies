import numpy as np
import matplotlib.pyplot as plt

# Define bandit for fixed or decaying epsilon values algorithm
class Epsilon_Bandit:
    def __init__(self, m):
        self.true_mean = m
        self.estimated_mean = 0
        self.N = 0
        
    # Pull a sample from the real data distribution of the bandit (modeled as a gaussian centered at <true_mean>)
    def pull(self):
        return np.random.randn() + self.true_mean
       
    # Update estimated mean using new sample pulled from real distribution
    def update(self, x):
        self.N += 1
        self.estimated_mean = (1 - 1.0/self.N)*self.estimated_mean + (1.0/self.N)*x
        
# Define bandit for optimistic initial values algorithm
class Optimistic_Bandit:
    def __init__(self, m, upper_limit):
        self.true_mean = m
        self.estimated_mean = upper_limit # Define upper 'optimistic' limit >> true_mean
        self.N = 0
        
    def pull(self):
        return np.random.randn() + self.true_mean
        
    def update(self, x): 
        self.N += 1
        self.estimated_mean = (1 - 1.0/self.N)*self.estimated_mean + (1.0/self.N)*x
      
# Define bandit for upper confidence bound interval algorithm
class Confidence_Interval_Bandit:
    def __init__(self, m):
        self.true_mean = m
        self.estimated_mean = 0
        self.N = 0.000001 # Initialize N with small number to avoid division by zero
        
    def pull(self):
        return np.random.randn() + self.true_mean
        
    def update(self, x): 
        self.N += 1
        self.estimated_mean = (1 - 1.0/self.N)*self.estimated_mean + (1.0/self.N)*x
       
# Define bandit for Thompson sampling algorithm 
class Bayesian_Bandit:
    def __init__(self, m):
        self.true_mean = m
        self.estimated_mean = 0
        self.estimated_precision = 1
        self.tau = 1
        self.sum_of_x = 0
        
    def pull(self):
        return np.random.randn() + self.true_mean
        
    # Return a sample from the estimated distribution
    def sample(self):
        return np.random.randn()/np.sqrt(self.estimated_precision) + self.estimated_mean
       
    # Update estimated distribution using new sample pulled from real distribution
    def update(self, x): 
        self.sum_of_x += x
        self.estimated_precision += self.tau
        self.estimated_mean = self.tau * self.sum_of_x / (self.estimated_precision)
        
def run_experiment_fixed_epsilon(m1, m2, m3, epsilon, N):
    
    bandits = [Epsilon_Bandit(m1), Epsilon_Bandit(m2), Epsilon_Bandit(m3)]
    data = np.empty(N)
        
    for i in range(N):
                
        random_number = np.random.random()
        
        # Chose random bandit with probability epsilon and bandit with largest estimated mean otherwise
        if random_number < epsilon:  # Epsilon is fixed
            idx_bandit = np.random.randint(3)
        else:
            idx_bandit = np.argmax([b.estimated_mean for b in bandits])
    
        x = bandits[idx_bandit].pull()
        bandits[idx_bandit].update(x)
    
        data[i] = x
        
    # Return cumulative average over pulled sample from chosen bandit
    cumulative_average = np.cumsum(data) / (np.arange(N) + 1)
        
    return cumulative_average

def run_experiment_decaying_epsilon(m1, m2, m3, N):
    
    bandits = [Epsilon_Bandit(m1), Epsilon_Bandit(m2), Epsilon_Bandit(m3)]
    data = np.empty(N)
        
    for i in range(N):
        
        # Epsilon decays with the number of steps
        epsilon = 1/(i+1)
        
        random_number = np.random.random()
        
        # Chose random bandit with probability epsilon and bandit with largest estimated mean otherwise  
        if random_number < epsilon: 
            idx_bandit = np.random.randint(3)
        else:
            idx_bandit = np.argmax([b.estimated_mean for b in bandits])
    
        x = bandits[idx_bandit].pull()
        bandits[idx_bandit].update(x)
    
        data[i] = x
        
    cumulative_average = np.cumsum(data) / (np.arange(N) + 1)
        
    return cumulative_average
    
def run_experiment_optimistic_value(m1, m2, m3, N):

    upper_limit = 10
    bandits = [Optimistic_Bandit(m1, upper_limit), Optimistic_Bandit(m2, upper_limit), Optimistic_Bandit(m3, upper_limit)]
    
    data = np.empty(N)
    
    for i in range(N):
    
        # Chose bandit with largest estimated mean
        idx_bandit = np.argmax([b.estimated_mean for b in bandits])
        
        x = bandits[idx_bandit].pull()
        bandits[idx_bandit].update(x)
        
        data[i] = x
        
    cumulative_average = np.cumsum(data) / (np.arange(N) + 1)
        
    return cumulative_average
        
def run_experiment_confidence_interval(m1, m2, m3, N):

    bandits = [Confidence_Interval_Bandit(m1), Confidence_Interval_Bandit(m2), Confidence_Interval_Bandit(m3)]
    
    data = np.empty(N)
    
    for i in range(N):
    
        # Chose bandit with largest 'mean + upper confidence bound interval' value
        idx_bandit = np.argmax([(b.estimated_mean + np.sqrt(2*np.log(i+1)/b.N)) for b in bandits])
        
        x = bandits[idx_bandit].pull()
        bandits[idx_bandit].update(x)
        
        data[i] = x
        
    cumulative_average = np.cumsum(data) / (np.arange(N) + 1)
        
    return cumulative_average
        
def run_experiment_bayesian(m1, m2, m3, N):

    bandits = [Bayesian_Bandit(m1), Bayesian_Bandit(m2), Bayesian_Bandit(m3)]
    
    data = np.empty(N)
    
    for i in range(N):
    
        # Chose bandit with highest sample value from estimated distributions
        idx_bandit = np.argmax([b.sample() for b in bandits])
        
        x = bandits[idx_bandit].pull()
        bandits[idx_bandit].update(x)
        
        data[i] = x
        
    cumulative_average = np.cumsum(data) / (np.arange(N) + 1)
        
    return cumulative_average

# Define true means
m1 = 1.0
m2 = 2.0
m3 = 3.0

# Define number of times to sample from bandits
N = 100000

# Plot cumulative averages 
plt.plot(run_experiment_fixed_epsilon(m1, m2, m3, 0.1, N), label = 'epsilon = 0.1')
plt.plot(run_experiment_fixed_epsilon(m1, m2, m3, 0.01, N), label = 'epsilon = 0.01')
plt.plot(run_experiment_decaying_epsilon(m1, m2, m3, N), label = 'decaying epsilon')
plt.plot(run_experiment_optimistic_value(m1, m2, m3, N), label = 'optimistic initial values')
plt.plot(run_experiment_confidence_interval(m1, m2, m3, N), label = 'upper confidence bound interval')
plt.plot(run_experiment_bayesian(m1, m2, m3, N), label = 'Thompson sampling')
plt.xscale('log')
plt.legend()
plt.show()

# Zoom-in
plt.plot(run_experiment_fixed_epsilon(m1, m2, m3, 0.1, N), label = 'epsilon = 0.1')
plt.plot(run_experiment_fixed_epsilon(m1, m2, m3, 0.01, N), label = 'epsilon = 0.01')
plt.plot(run_experiment_decaying_epsilon(m1, m2, m3, N), label = 'decaying epsilon')
plt.plot(run_experiment_optimistic_value(m1, m2, m3, N), label = 'optimistic initial values')
plt.plot(run_experiment_confidence_interval(m1, m2, m3, N), label = 'upper confidence bound interval')
plt.plot(run_experiment_bayesian(m1, m2, m3, N), label = 'Thompson sampling')
plt.legend()
plt.axis([10**4, 10**5, 2.85, 3.05])
plt.show()
